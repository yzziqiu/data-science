{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "from __future__ import division, print_function\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/izzyqiu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers import LSTM, Dropout, Dense, Conv1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('amazon-fine-food-reviews/Reviews.csv')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      "Id                        568454 non-null int64\n",
      "ProductId                 568454 non-null object\n",
      "UserId                    568454 non-null object\n",
      "ProfileName               568438 non-null object\n",
      "HelpfulnessNumerator      568454 non-null int64\n",
      "HelpfulnessDenominator    568454 non-null int64\n",
      "Score                     568454 non-null int64\n",
      "Time                      568454 non-null int64\n",
      "Summary                   568428 non-null object\n",
      "Text                      568454 non-null object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 4, 2, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.Score.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a41f12a58>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAADwCAYAAADmUNj0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMBgRAAADEYEAMBg/w9DW1d88Qo9OgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a41f122b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews.Score.value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM models for review classification and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51014 unique tokens.\n",
      "Shape of data tensor: (70000, 500)\n",
      "Shape of label tensor: (70000,)\n",
      "fraction 5 star in sample:  0.6261571428571429\n",
      "fraction 5 star in test set:  0.637\n",
      "CPU times: user 11.6 s, sys: 2.94 s, total: 14.5 s\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# using tensorflow to get tokenizer\n",
    "seq_length = 500 #padding/cut to this length\n",
    "num_samples = 70000\n",
    "texts = reviews.iloc[:num_samples].Text\n",
    "#remove html line breaks\n",
    "text = array([re.sub('<[^<]+?>', '', x) for x in texts])\n",
    "\n",
    "#labels = reviews.iloc[:50000].Score-1 \n",
    "labels = reviews.Score.apply(lambda x: x>4).iloc[:num_samples] #shift to start counting with 0\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 10000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen= seq_length)\n",
    "\n",
    "labels = labels.astype(int)\n",
    "#labels = to_categorical(np.asarray(labels), num_classes= 5)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(.1 * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]\n",
    "\n",
    "print(\"fraction 5 star in sample: \", sum(labels)/num_samples)\n",
    "print(\"fraction 5 star in test set: \", mean(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    1,  493,  108, 2986,  281,    2,  170,  514,  157,  199,\n",
       "         22,   77,    5,   91,    3,  157,   64,   29,   22,   33, 1251,\n",
       "         34,   25,   13, 4034,   78,    5,   91,  149,    3,   32,   13,\n",
       "       2294, 1328,   79,  435,   35,  545,   24,    1,  485, 8725,    2,\n",
       "        282, 4167,    9,   39,  555], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100 #given GloVe fileb\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length = seq_length,\n",
    "                            trainable=True,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 32)           320000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 405,665\n",
      "Trainable params: 405,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 63000 samples, validate on 7000 samples\n",
      "Epoch 1/3\n",
      "63000/63000 [==============================] - 667s 11ms/step - loss: 0.4650 - acc: 0.7830 - val_loss: 0.3879 - val_acc: 0.8387\n",
      "Epoch 2/3\n",
      "63000/63000 [==============================] - 647s 10ms/step - loss: 0.3643 - acc: 0.8497 - val_loss: 0.3832 - val_acc: 0.8426\n",
      "Epoch 3/3\n",
      "63000/63000 [==============================] - 569s 9ms/step - loss: 0.3165 - acc: 0.8763 - val_loss: 0.3884 - val_acc: 0.8397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3f373668>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "#model.add(embedding_layer)\n",
    "model.add(Embedding(10000, embedding_vecor_length, input_length = data.shape[1]))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate review text (five stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13978 unique tokens.\n",
      "Total Patterns:  289056\n",
      "CPU times: user 1.04 s, sys: 124 ms, total: 1.17 s\n",
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text = reviews[reviews.Score == 5].iloc[:5000].Text\n",
    "# periods as words\n",
    "#text = array([string.replace(x, '.', \" .\") for x in text])\n",
    "\n",
    "#remove html line breaks\n",
    "text = array([re.sub('<[^<]+?>', '', x) for x in text])\n",
    "\n",
    "num_words = 800\n",
    "tokenizer = Tokenizer(num_words = num_words, filters='!\"#$%&()*+,.-/:;<=>?@[\\\\]^_`{|}~\\t\\n)')\n",
    "tokenizer.fit_on_texts(text)\n",
    "concat_text = tokenizer.texts_to_sequences(text)\n",
    "concat_text = array([item for sublist in concat_text for item in sublist])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "# for later text generation: int->word dictionary\n",
    "inv_word_index = {v: k for k, v in word_index.items()}\n",
    "\n",
    "## training sequences of length 5\n",
    "seq_length = 6\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(concat_text) - seq_length, 1):\n",
    "    seq_in = concat_text[i:i + seq_length]\n",
    "    seq_out = concat_text[i + seq_length]\n",
    "    dataX.append(seq_in)\n",
    "    dataY.append(seq_out)\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100 #given GloVe fileb\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length = seq_length,\n",
    "                            trainable=True,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Small LSTM Network to Generate Text for Alice in Wonderland\n",
    "# reshape X to be [samples, time steps, features]\n",
    "#X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length)) #if embedding is first layer\n",
    "# normalize\n",
    "#X = X / float(num_words)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "# define the LSTM model\n",
    "embedding_vecor_length = 16\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "# add second LSTM layer\n",
    "#if True:\n",
    "    #model.add(Embedding(num_words, embedding_vecor_length, input_length = X.shape[1]))\n",
    "    #model.add(LSTM(128, return_sequences = True))#, input_shape=(X.shape[1], X.shape[2])))\n",
    "    #model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))#, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GaussianNoise(.15))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "289024/289056 [============================>.] - ETA: 0s - loss: 5.1476Epoch 00001: loss improved from inf to 5.14757, saving model to weights-improvement-01-5.1476.hdf5\n",
      "289056/289056 [==============================] - 320s 1ms/step - loss: 5.1476\n",
      "Epoch 2/4\n",
      "289024/289056 [============================>.] - ETA: 0s - loss: 4.6341Epoch 00002: loss improved from 5.14757 to 4.63408, saving model to weights-improvement-02-4.6341.hdf5\n",
      "289056/289056 [==============================] - 279s 967us/step - loss: 4.6341\n",
      "Epoch 3/4\n",
      "289024/289056 [============================>.] - ETA: 0s - loss: 4.4743Epoch 00003: loss improved from 4.63408 to 4.47433, saving model to weights-improvement-03-4.4743.hdf5\n",
      "289056/289056 [==============================] - 274s 948us/step - loss: 4.4743\n",
      "Epoch 4/4\n",
      "289024/289056 [============================>.] - ETA: 0s - loss: 4.3669Epoch 00004: loss improved from 4.47433 to 4.36688, saving model to weights-improvement-04-4.3669.hdf5\n",
      "289056/289056 [==============================] - 255s 882us/step - loss: 4.3669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a61e81cf8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(X, y, epochs= 4, batch_size = 128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (Unable to open file: name = 'weights-improvement-03-4.2355.hdf5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-3e8d7e33ee69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# load the network weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"weights-improvement-03-4.2355.hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (Unable to open file: name = 'weights-improvement-03-4.2355.hdf5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "# load the network weights\n",
    "filename = \"weights-improvement-03-4.2355.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: are some rice treats sure can ...\n",
      "be a little bit and i love it i am a fan of the coffee and the taste of the and i love it too i am a big hit and it was so easy to get the same price for the first time i have been using it for \n",
      "\n",
      "seed: in place of so i have ...\n",
      "been a few of the past and they have a great taste and a good product and the flavor is very good but i have a of this product i have had been able to find this one in my local i love these they are the best i've ever \n",
      "\n",
      "seed: they are light but not their ...\n",
      "favorite the is the only thing that you could find it again and i have a little of this stuff i was so happy that i can get the best that i can make a great snack i have had a few years ago i had to get it to \n",
      "\n",
      "seed: really flavor that you in a ...\n",
      "i am so happy to find it in the i love it i love this coffee it works great to the i have been drinking for my for years old i love these chips i am hooked i love them and the taste of the best coffee i've tried many \n",
      "\n",
      "seed: flavor quality of cookie overall is ...\n",
      "the best tasting i have found it in a while i love the taste of these chips the taste is the best tasting chocolate and they have the best of the of the other flavors i have tried the flavor and the price is the best tasting coffee and i \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "for _ in range(5):\n",
    "    start = numpy.random.randint(0, len(dataX)-1)\n",
    "    pattern = dataX[start]\n",
    "    print(\"seed:\" , ' '.join([inv_word_index[value] for value in pattern]), \"...\")\n",
    "    # generate characters\n",
    "    for i in range(50):\n",
    "        x = numpy.reshape(pattern, (1, len(pattern)))\n",
    "        #prediction = model.predict(x, verbose=0)\n",
    "        #index = numpy.argmax(prediction)\n",
    "        p = model.predict_proba(x, verbose = 0)[0]\n",
    "        p[1] /= 1\n",
    "        top_ind = argsort(p)[::-1][:5] #extract lergest probabilities\n",
    "        #print top_ind\n",
    "        p = p[top_ind]\n",
    "        p /= sum(p)\n",
    "        #print p\n",
    "        index = random.choice(top_ind, 1, p = p)[0]\n",
    "        #print sum(prediction[0]**2)\n",
    "        result = inv_word_index[index]\n",
    "        seq_in = [inv_word_index[value] for value in pattern]\n",
    "        sys.stdout.write(result+' ')\n",
    "        pattern = append(pattern, index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "        #print pattern\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
